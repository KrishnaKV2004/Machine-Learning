{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Data Preprocessing -->\n",
    "\n",
    "    Data preprocessing in machine learning (ML) is the process of transforming raw data into a clean\n",
    "    and structured format that can be effectively used by machine learning models. It is a crucial step\n",
    "    in the ML pipeline, as raw data often contains inconsistencies, missing values, noise, or irrelevant\n",
    "    features that can negatively impact model performance\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Key Steps To Clean Data -->\n",
    "\n",
    "    1.  Data Cleaning ->\n",
    "\n",
    "    +   Handling Missing Values ->\n",
    "        Filling in missing data with mean/median values, or removing rows/columns with missing data\n",
    "\n",
    "    +   Removing Noise ->\n",
    "        Filtering out outliers or errors that can distort the analysis\n",
    "\n",
    "    +   Correcting Inconsistencies ->\n",
    "        Fixing data entry errors or formatting issues\n",
    "\n",
    "    2.  Data Integration ->\n",
    "\n",
    "        Combining data from multiple sources or tables into a cohesive dataset, ensuring that relationships\n",
    "        between data points are preserved\n",
    "\n",
    "    3.  Data Transformation ->\n",
    "\n",
    "    +   Normalization/Standardization ->\n",
    "        Scaling data to a standard range (e.g., 0 to 1) or to have a mean of zero and a standard deviation\n",
    "        of one, making it easier for the model to learn patterns\n",
    "\n",
    "    +   Encoding Categorical Variables ->\n",
    "        Converting categorical data into numerical format using techniques like one-hot encoding or label\n",
    "        encoding\n",
    "\n",
    "    +   Feature Engineering ->\n",
    "        Creating new features that might help the model perform better by combining or transforming\n",
    "        existing features\n",
    "\n",
    "    4.  Data Reduction ->\n",
    "\n",
    "    +   Dimensionality Reduction ->\n",
    "        Reducing the number of features using techniques like Principal Component Analysis (PCA) to\n",
    "        focus on the most important features and reduce the complexity of the model\n",
    "\n",
    "    +   Feature Selection ->\n",
    "        Choosing only the most relevant features for model training to avoid overfitting and improve\n",
    "        model interpretability\n",
    "\n",
    "    5.  Data Splitting ->\n",
    "\n",
    "        Dividing the dataset into training, validation, and test sets to evaluate model performance and\n",
    "        generalization ability\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
