{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Logistic Regression -->\n",
    "    \n",
    "    Logistic Regression is a supervised machine learning algorithm used for binary\n",
    "    and multi-class classification problems. It predicts probabilities and classifies data\n",
    "    based on a threshold (usually 0.5). Despite its name, Logistic Regression is a\n",
    "    classification algorithm, not a regression algorithm.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Source/Logistic Regression.png' alt='Graph' style=\"width:700px; height:auto; margin-left:40px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Source/Process.png' alt='Graph' style=\"width:500px; height:auto; margin-left:40px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Problems -->\n",
    "    \n",
    "    Linear Decision Boundary :\n",
    "\n",
    "    Assumes a linear relationship between the independent variables and the log-odds of the target.\n",
    "    Fails to perform well with non-linear relationships unless transformed features or kernels are used.\n",
    "\n",
    "    Sensitive to Multicollinearity :\n",
    "\n",
    "    Poor performance when independent variables are highly correlated unless addressed (e.g., using PCA).\n",
    "    \n",
    "    Performance with Imbalanced Data :\n",
    "\n",
    "    Struggles with datasets where classes are highly imbalanced unless handled with techniques\n",
    "    like oversampling or class weighting.\n",
    "\n",
    "    Feature Engineering Dependence :\n",
    "\n",
    "    Requires careful feature engineering, scaling, and selection for optimal performance.\n",
    "    \n",
    "    Assumes Independence of Features :\n",
    "\n",
    "    Assumes that features are not highly dependent on one another, which may not hold in real-world data.\n",
    "\n",
    "    Limited to Linearly Separable Data :\n",
    "\n",
    "    Struggles to classify datasets where classes are not linearly separable.\n",
    "    \n",
    "    Not Suitable for Large Number of Features :\n",
    "\n",
    "    While efficient, it might not scale well for datasets with a very large number of irrelevant or\n",
    "    redundant features without proper preprocessing.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    When to Use Logistic Regression -->\n",
    "    \n",
    "    Logistic regression is ideal for :\n",
    "\n",
    "    Problems requiring simple, interpretable models.\n",
    "    Binary or multi-class classification with linearly separable data.\n",
    "    Datasets with fewer features and no strong multicollinearity.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Applications of Logistic Regression -->\n",
    "    \n",
    "    Binary Classification :\n",
    "\n",
    "    Spam detection (spam vs. not spam)\n",
    "    Disease prediction (has disease vs. doesn't have disease)\n",
    "    \n",
    "    Multi-Class Classification (with extensions like one-vs-rest or multinomial logistic regression) :\n",
    "\n",
    "    Handwritten digit recognition\n",
    "    Customer segmentation\n",
    "\n",
    "    Real-world Applications :\n",
    "\n",
    "    Credit scoring\n",
    "    Marketing campaigns\n",
    "    Fraud detection\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
